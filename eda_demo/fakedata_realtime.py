"""
Gá»­i nhiá»u requests Ä‘á»“ng thá»i Ä‘á»ƒ test real-time processing
Sá»­ dá»¥ng ThreadPoolExecutor Ä‘á»ƒ gá»­i parallel requests
"""
import requests
import time
import random
from faker import Faker
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime

fake = Faker()

API_URL = "http://localhost:8000/orders/"

# Cáº¥u hÃ¬nh
NUM_MESSAGES = 100  # Tá»•ng sá»‘ messages
NUM_WORKERS = 10    # Sá»‘ threads cháº¡y Ä‘á»“ng thá»i
BATCH_SIZE = 20     # Gá»­i theo batch Ä‘á»ƒ dá»… quan sÃ¡t

def send_single_request(request_id):
    """
    Gá»­i 1 request Ä‘áº¿n API
    
    Args:
        request_id: ID Ä‘á»ƒ tracking
        
    Returns:
        dict: Káº¿t quáº£ request
    """
    data = {
        "product": fake.word().capitalize(),
        "quantity": random.randint(1, 10)
    }
    
    # Táº¡o idempotency key (optional - Ä‘á»ƒ test duplicate prevention)
    idempotency_key = f"req-{request_id}-{int(time.time())}"
    
    headers = {
        "Content-Type": "application/json",
        "X-Idempotency-Key": idempotency_key
    }
    
    start_time = time.time()
    
    try:
        response = requests.post(API_URL, json=data, headers=headers, timeout=10)
        elapsed = time.time() - start_time
        
        result = {
            "request_id": request_id,
            "status_code": response.status_code,
            "elapsed_time": round(elapsed, 3),
            "success": response.status_code in [200, 201],
            "data": response.json() if response.status_code in [200, 201] else None,
            "error": None
        }
        
        print(f"âœ… Request #{request_id}: {response.status_code} - {elapsed:.3f}s - {data['product']}")
        return result
        
    except requests.exceptions.Timeout:
        elapsed = time.time() - start_time
        print(f"â±ï¸  Request #{request_id}: TIMEOUT after {elapsed:.3f}s")
        return {
            "request_id": request_id,
            "status_code": None,
            "elapsed_time": round(elapsed, 3),
            "success": False,
            "data": None,
            "error": "Timeout"
        }
        
    except Exception as e:
        elapsed = time.time() - start_time
        print(f"âŒ Request #{request_id}: ERROR - {str(e)}")
        return {
            "request_id": request_id,
            "status_code": None,
            "elapsed_time": round(elapsed, 3),
            "success": False,
            "data": None,
            "error": str(e)
        }

def send_batch(batch_num, batch_size, num_workers):
    """
    Gá»­i 1 batch requests Ä‘á»“ng thá»i
    
    Args:
        batch_num: Sá»‘ thá»© tá»± batch
        batch_size: Sá»‘ requests trong batch
        num_workers: Sá»‘ threads cháº¡y Ä‘á»“ng thá»i
    """
    print(f"\n{'='*70}")
    print(f"ğŸ“¦ BATCH {batch_num}: Sending {batch_size} requests with {num_workers} workers")
    print(f"{'='*70}")
    
    batch_start = time.time()
    results = []
    
    # Sá»­ dá»¥ng ThreadPoolExecutor Ä‘á»ƒ gá»­i concurrent requests
    with ThreadPoolExecutor(max_workers=num_workers) as executor:
        # Submit táº¥t cáº£ requests
        futures = []
        for i in range(batch_size):
            request_id = (batch_num - 1) * batch_size + i + 1
            future = executor.submit(send_single_request, request_id)
            futures.append(future)
        
        # Äá»£i táº¥t cáº£ requests hoÃ n thÃ nh
        for future in as_completed(futures):
            result = future.result()
            results.append(result)
    
    batch_elapsed = time.time() - batch_start
    
    # Thá»‘ng kÃª
    success_count = sum(1 for r in results if r["success"])
    failed_count = len(results) - success_count
    avg_time = sum(r["elapsed_time"] for r in results) / len(results)
    max_time = max(r["elapsed_time"] for r in results)
    min_time = min(r["elapsed_time"] for r in results)
    
    print(f"\n{'='*70}")
    print(f"ğŸ“Š BATCH {batch_num} SUMMARY:")
    print(f"   Total requests: {len(results)}")
    print(f"   âœ… Success: {success_count}")
    print(f"   âŒ Failed: {failed_count}")
    print(f"   â±ï¸  Batch time: {batch_elapsed:.3f}s")
    print(f"   ğŸ“ˆ Avg response time: {avg_time:.3f}s")
    print(f"   âš¡ Min response time: {min_time:.3f}s")
    print(f"   ğŸŒ Max response time: {max_time:.3f}s")
    print(f"   ğŸš€ Throughput: {len(results)/batch_elapsed:.2f} req/s")
    print(f"{'='*70}\n")
    
    return results

def main():
    """Main function Ä‘á»ƒ cháº¡y demo"""
    print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           CONCURRENT REQUESTS LOAD TEST                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Configuration:
  â€¢ Total messages: {NUM_MESSAGES}
  â€¢ Concurrent workers: {NUM_WORKERS}
  â€¢ Batch size: {BATCH_SIZE}
  â€¢ API endpoint: {API_URL}

Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
    """)
    
    overall_start = time.time()
    all_results = []
    
    # TÃ­nh sá»‘ batch cáº§n gá»­i
    num_batches = (NUM_MESSAGES + BATCH_SIZE - 1) // BATCH_SIZE
    
    for batch_num in range(1, num_batches + 1):
        # Batch cuá»‘i cÃ³ thá»ƒ Ã­t hÆ¡n BATCH_SIZE
        remaining = NUM_MESSAGES - (batch_num - 1) * BATCH_SIZE
        current_batch_size = min(BATCH_SIZE, remaining)
        
        batch_results = send_batch(batch_num, current_batch_size, NUM_WORKERS)
        all_results.extend(batch_results)
        
        # Delay giá»¯a cÃ¡c batch Ä‘á»ƒ dá»… quan sÃ¡t
        if batch_num < num_batches:
            print(f"â³ Waiting 3 seconds before next batch...\n")
            time.sleep(3)
    
    overall_elapsed = time.time() - overall_start
    
    # Tá»•ng káº¿t cuá»‘i cÃ¹ng
    total_success = sum(1 for r in all_results if r["success"])
    total_failed = len(all_results) - total_success
    overall_avg_time = sum(r["elapsed_time"] for r in all_results) / len(all_results)
    
    print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    OVERALL SUMMARY                            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Total Statistics:
  â€¢ Total requests sent: {len(all_results)}
  â€¢ âœ… Successful: {total_success} ({total_success/len(all_results)*100:.1f}%)
  â€¢ âŒ Failed: {total_failed} ({total_failed/len(all_results)*100:.1f}%)
  â€¢ â±ï¸  Total time: {overall_elapsed:.2f}s
  â€¢ ğŸ“ˆ Average response time: {overall_avg_time:.3f}s
  â€¢ ğŸš€ Overall throughput: {len(all_results)/overall_elapsed:.2f} req/s

Finished at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
    """)
    
    # LÆ°u káº¿t quáº£ ra file (optional)
    try:
        with open('load_test_results.txt', 'w') as f:
            f.write(f"Load Test Results - {datetime.now()}\n")
            f.write(f"Total: {len(all_results)}, Success: {total_success}, Failed: {total_failed}\n\n")
            for r in all_results:
                f.write(f"Request {r['request_id']}: {r['status_code']} - {r['elapsed_time']}s\n")
        print("ğŸ“ Results saved to load_test_results.txt")
    except Exception as e:
        print(f"âš ï¸  Could not save results: {e}")

if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  Test interrupted by user")
    except Exception as e:
        print(f"\n\nâŒ Fatal error: {e}")