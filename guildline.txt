==================================================================
EVENT-DRIVEN ARCHITECTURE DEMO WITH DJANGO + KAFKA + CELERY
==================================================================

üìã PREREQUISITES
- Docker Desktop installed
- Python 3.8+ installed
- PowerShell or Terminal

==================================================================
1. SETUP - FIRST TIME ONLY
==================================================================

A. Start Infrastructure (Kafka + Redis)
----------------------------------------
docker-compose up -d

# Ki·ªÉm tra containers ƒëang ch·∫°y:
docker ps

# Ki·ªÉm tra logs:
docker logs -f kafka
docker logs -f redis

B. Install Python Dependencies
----------------------------------------
pip install -r requirements.txt

C. Database Setup
----------------------------------------
python manage.py makemigrations
python manage.py migrate

D. Create Kafka Topics
----------------------------------------
# V√†o container Kafka:
docker exec -it kafka bash

# T·∫°o topic orders (3 partitions):
/opt/kafka/bin/kafka-topics.sh --create --topic orders --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1

# T·∫°o topic Dead Letter Queue:
/opt/kafka/bin/kafka-topics.sh --create --topic orders-dlq --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1

# Ki·ªÉm tra topics ƒë√£ t·∫°o:
/opt/kafka/bin/kafka-topics.sh --list --bootstrap-server localhost:9092

# Exit container:
exit

E. Truy c·∫≠p Kafka UI
----------------------------------------
M·ªü browser: http://localhost:8080
- Xem topics, partitions, consumer groups
- Monitor messages flow

==================================================================
2. RUNNING THE DEMO
==================================================================

B·∫°n c·∫ßn m·ªü 6 c·ª≠a s·ªï PowerShell/Terminal ri√™ng bi·ªát:

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ C·ª¨A S·ªî 1: Django API Server                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
python manage.py runserver

# API s·∫Ω ch·∫°y t·∫°i: http://127.0.0.1:8000


‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ C·ª¨A S·ªî 2: Celery Worker (X·ª≠ l√Ω async tasks)                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
celery -A eda_demo worker --loglevel=info --pool=solo

# Windows user: ph·∫£i d√πng --pool=solo
# Linux/Mac user: c√≥ th·ªÉ b·ªè --pool=solo


‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ C·ª¨A S·ªî 3: Inventory Consumer                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
cd orders/consumers
python inventory.py


‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ C·ª¨A S·ªî 4: Notification Consumer                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
cd orders/consumers
python notification.py


‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ C·ª¨A S·ªî 5: Analytics Consumer                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
cd orders/consumers
python analytics.py


‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ C·ª¨A S·ªî 6: Sending Test Data                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
# Option 1: T·ª± ƒë·ªông g·ª≠i nhi·ªÅu requests
python fakedata.py

# Option 2: G·ª≠i request th·ªß c√¥ng b·∫±ng curl/Postman
curl -X POST http://127.0.0.1:8000/orders/ ^
  -H "Content-Type: application/json" ^
  -d "{\"product\": \"Laptop\", \"quantity\": 2}"

# Option 3: Test idempotency
curl -X POST http://127.0.0.1:8000/orders/ ^
  -H "Content-Type: application/json" ^
  -H "X-Idempotency-Key: test-key-123" ^
  -d "{\"product\": \"Mouse\", \"quantity\": 5}"

==================================================================
3. TESTING & MONITORING
==================================================================

A. Check Order Status
----------------------------------------
# L·∫•y status c·ªßa order ID = 1
curl http://127.0.0.1:8000/orders/1/status/

Response:
{
  "order_id": 1,
  "status": "completed",
  "event_published": true,
  "inventory_processed": true,
  "notification_sent": true,
  "analytics_recorded": true
}

B. Health Check
----------------------------------------
curl http://127.0.0.1:8000/health/

Response:
{
  "status": "healthy",
  "services": {
    "database": "healthy",
    "kafka": "healthy",
    "celery": "healthy"
  }
}

C. Monitor Kafka UI
----------------------------------------
M·ªü: http://localhost:8080
- Topics ‚Üí orders: Xem messages ƒë√£ g·ª≠i
- Consumer Groups: Xem offset c·ªßa t·ª´ng consumer

D. Monitor Celery
----------------------------------------
# Trong c·ª≠a s·ªï m·ªõi:
celery -A eda_demo inspect active
celery -A eda_demo inspect stats

==================================================================
4. DEMO FLOW EXPLANATION
==================================================================

ASYNCHRONOUS FLOW (X·ª≠ l√Ω b·∫•t ƒë·ªìng b·ªô):
---------------------------------------

1. Client g·ª≠i POST request ‚Üí Django API
   ‚îî‚îÄ> Response tr·∫£ v·ªÅ NGAY L·∫¨P T·ª®C (201 Created)
   ‚îî‚îÄ> Task ID ƒë∆∞·ª£c t·∫°o cho background processing

2. Celery Worker nh·∫≠n task t·ª´ Redis queue
   ‚îî‚îÄ> Publish event to Kafka
   ‚îî‚îÄ> C·∫≠p nh·∫≠t order status = "processing"

3. Kafka nh·∫≠n event ‚Üí Distribute ƒë·∫øn 3 consumers
   ‚îî‚îÄ> Inventory Consumer (Consumer Group 1)
   ‚îî‚îÄ> Notification Consumer (Consumer Group 2)
   ‚îî‚îÄ> Analytics Consumer (Consumer Group 3)

4. M·ªói consumer x·ª≠ l√Ω ƒë·ªôc l·∫≠p:
   ‚îú‚îÄ> Inventory: Trigger Celery task ‚Üí Update stock
   ‚îú‚îÄ> Notification: Trigger Celery task ‚Üí Send email
   ‚îî‚îÄ> Analytics: Trigger Celery task ‚Üí Record metrics

5. Sau khi t·∫•t c·∫£ tasks ho√†n th√†nh:
   ‚îî‚îÄ> Order status = "completed"

BENEFITS OF THIS ARCHITECTURE:
-------------------------------
‚úÖ Non-blocking: API response ngay l·∫≠p t·ª©c
‚úÖ Scalable: C√≥ th·ªÉ ch·∫°y nhi·ªÅu workers/consumers
‚úÖ Resilient: Retry mechanism + Dead Letter Queue
‚úÖ Decoupled: Services kh√¥ng ph·ª• thu·ªôc v√†o nhau
‚úÖ Idempotent: Tr√°nh x·ª≠ l√Ω tr√πng l·∫∑p

==================================================================
5. ERROR HANDLING & RETRY
==================================================================

A. Automatic Retry
----------------------------------------
- Celery tasks t·ª± ƒë·ªông retry 3 l·∫ßn n·∫øu failed
- Delay gi·ªØa c√°c retry: 60 seconds
- Sau 3 l·∫ßn retry fail ‚Üí G·ª≠i ƒë·∫øn Dead Letter Queue

B. Dead Letter Queue
----------------------------------------
# Xem messages trong DLQ:
docker exec -it kafka bash
/opt/kafka/bin/kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 \
  --topic orders-dlq \
  --from-beginning

C. Manual Offset Reset
----------------------------------------
# N·∫øu consumer b·ªã stuck, reset offset:
docker exec -it kafka bash
/opt/kafka/bin/kafka-consumer-groups.sh \
  --bootstrap-server localhost:9092 \
  --group eda-demo-inventory \
  --reset-offsets \
  --to-earliest \
  --topic orders \
  --execute

==================================================================
6. STOP & CLEANUP
==================================================================

A. Stop All Services
----------------------------------------
# Stop Django: Ctrl+C
# Stop Celery Worker: Ctrl+C
# Stop Consumers: Ctrl+C (x3)

B. Stop Docker Containers
----------------------------------------
docker-compose down

# N·∫øu mu·ªën x√≥a volumes (data s·∫Ω m·∫•t):
docker-compose down -v

C. Clean Database
----------------------------------------
# X√≥a database file:
del db.sqlite3

# X√≥a migrations:
del orders\migrations\0001_initial.py

==================================================================
7. TROUBLESHOOTING
==================================================================

Problem: Celery kh√¥ng connect ƒë∆∞·ª£c Redis
Solution:
  - Ki·ªÉm tra Redis: docker logs redis
  - Ki·ªÉm tra port 6379: netstat -ano | findstr 6379
  - Restart Redis: docker restart redis

Problem: Consumer kh√¥ng nh·∫≠n ƒë∆∞·ª£c messages
Solution:
  - Ki·ªÉm tra topic exists: kafka-topics.sh --list
  - Ki·ªÉm tra consumer group: kafka-consumer-groups.sh --list
  - Reset offset v·ªÅ earliest (xem section 5C)

Problem: Celery task b·ªã stuck
Solution:
  - Xem active tasks: celery -A eda_demo inspect active
  - Purge queue: celery -A eda_demo purge
  - Restart worker

Problem: Port already in use
Solution:
  - Ki·ªÉm tra process: netstat -ano | findstr <PORT>
  - Kill process: taskkill /PID <PID> /F

==================================================================
8. PRODUCTION CONSIDERATIONS
==================================================================

‚ö†Ô∏è  Nh·ªØng ƒëi·ªÅu c·∫ßn thay ƒë·ªïi khi deploy production:

1. Security:
   - ƒê·ªïi SECRET_KEY trong settings.py
   - Set DEBUG = False
   - Configure ALLOWED_HOSTS
   - Use environment variables

2. Database:
   - ƒê·ªïi t·ª´ SQLite sang PostgreSQL/MySQL
   - Setup connection pooling

3. Kafka:
   - Setup multiple brokers (cluster)
   - Configure replication factor > 1
   - Enable authentication (SASL/SSL)

4. Celery:
   - Use RabbitMQ instead of Redis (more reliable)
   - Configure max_retries per task type
   - Setup Flower for monitoring

5. Monitoring:
   - Add Prometheus + Grafana
   - Setup alerting (PagerDuty, Slack)
   - Log aggregation (ELK stack)

6. Load Balancing:
   - Nginx/HAProxy for Django
   - Multiple Celery workers
   - Multiple Kafka consumers per group

==================================================================
HAPPY CODING! üöÄ
==================================================================